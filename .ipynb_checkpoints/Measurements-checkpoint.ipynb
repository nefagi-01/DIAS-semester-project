{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32df540d-f2df-4d0a-b5cd-52d115cd74e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from KMeans import *\n",
    "from openml.datasets import list_datasets, get_datasets\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy import stats\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c09270-7bbd-49a1-a42b-071b5dc2ddd4",
   "metadata": {},
   "source": [
    "## Flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b06df284-e48e-47d7-bd5b-a09553cab042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flag for researching datasets\n",
    "search = False\n",
    "# flag for re-measuring time executions\n",
    "measure = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352f6cee-cfb1-4778-9030-d9fbf595753c",
   "metadata": {},
   "source": [
    "## Dataset retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcbe170d-8f4d-4b6b-b37e-bfa0593ea3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if search:\n",
    "    query = \"NumberOfInstances > 100000 &\\\n",
    "             NumberOfInstances < 1000000 &\\\n",
    "             NumberOfNumericFeatures > 3 &\\\n",
    "             NumberOfNumericFeatures < 25 &\\\n",
    "             NumberOfMissingValues == 0 &\\\n",
    "             NumberOfSymbolicFeatures == 0\"\n",
    "\n",
    "    dataset_dataframe = list_datasets(output_format=\"dataframe\").query(query)\n",
    "    dataset_dataframe = dataset_dataframe.drop_duplicates(['name']).drop_duplicates(['NumberOfNumericFeatures']).sort_values(by=['NumberOfNumericFeatures'])\n",
    "    dataset_ids = dataset_dataframe['did'][:10]\n",
    "    dataset_ids.to_csv('./data/dataset_ids.csv', index=False)\n",
    "dataset_ids = pd.read_csv('./data/dataset_ids.csv')['did']\n",
    "dataset_list = get_datasets(dataset_ids=dataset_ids)\n",
    "X_list = [dataset.get_data()[0].select_dtypes([np.number]).to_numpy() for dataset in dataset_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abece96d-f26a-4e2c-8b6b-cdada0d9f072",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Plot definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9e0bb23-f216-44fb-84a5-1f7a1c1dffe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad = 20\n",
    "figsize = (10,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fc5cd1b-f6f6-4403-a74e-5ac2df86adb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxplot(df, columns, title, xlabel, ylabel, tick_freq=None):\n",
    "    plt.figure(figsize=figsize)\n",
    "    df_melted = pd.melt(df, value_vars=columns)\n",
    "    ax = sns.boxplot(x=\"variable\", y=\"value\", data=df_melted)\n",
    "    ax.set_title(title, pad=pad)\n",
    "    if tick_freq is not None:\n",
    "        ax.yaxis.set_major_locator(ticker.MultipleLocator(tick_freq))\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "824adf75-0f78-4021-87c6-e1bfa86fdabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatterplot(df, x, y, title, xlabel, ylabel):\n",
    "    plt.figure(figsize=figsize)\n",
    "    ax = sns.scatterplot(data=df, x=x, y=y)\n",
    "    ax.set_title(title, pad=pad)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77ab8f81-9b0c-49c5-8888-977c39c1ca26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPlots(df, speculation=False):\n",
    "    sns.set_context(\"paper\", font_scale=1.5)\n",
    "\n",
    "    df['ratio_AB_median'] = df['t_A_median']/df['t_B_median']\n",
    "    \n",
    "    # Box-plot of medians\n",
    "    if speculation:\n",
    "        boxplot(df, columns = ['t_A_median', 't_B_median', 't_correction_median', 't_speculation_median'], title = 'Average execution time of A, B, correction and speculation', xlabel = 'Task', ylabel = 'Execution time in ns', tick_freq=0.05)\n",
    "        \n",
    "    else:\n",
    "        boxplot(df, columns = ['t_A_median', 't_B_median'],  title = 'Average execution time of A, B', xlabel = 'Task', ylabel = 'Execution time in ns', tick_freq=0.05)\n",
    "        \n",
    "    # Box-plot of ratios\n",
    "    if speculation:\n",
    "        df_measurements_speculation['ratio_A_correction_median'] = df_measurements_speculation['t_A_median']/df_measurements_speculation['t_correction_median']\n",
    "        df_measurements_speculation['ratio_B_correction_median'] = df_measurements_speculation['t_B_median']/df_measurements_speculation['t_correction_median']\n",
    "        df_measurements_speculation['ratio_B_speculation_median'] = df_measurements_speculation['t_B_median']/df_measurements_speculation['t_speculation_median']\n",
    "        boxplot(df, columns = ['ratio_AB_median'], title = r'Ratio $\\frac{median(t_A)}{median(t_B)}$', xlabel = 'Task', ylabel = 'Ratio value', tick_freq=20)\n",
    "        boxplot(df, columns = ['ratio_A_correction_median'], title = r'Ratio $\\frac{median(t_A)}{median(t_{correction})}$', xlabel = 'Task', ylabel = 'Ratio value', tick_freq=20)\n",
    "        boxplot(df, columns = ['ratio_B_correction_median', 'ratio_B_speculation_median'], title = r'Ratio $\\frac{median(t_B)}{median(t_{correction})}$ and Ratio $\\frac{median(t_B)}{median(t_{speculation})}$', xlabel = 'Task', ylabel = 'Ratio value', tick_freq=5)\n",
    "\n",
    "    else:\n",
    "        boxplot(df, columns = ['ratio_AB_median'], title = r'Ratio $\\frac{median(t_A)}{median(t_B)}$', xlabel = 'Task', ylabel = 'Ratio value', tick_freq=5)\n",
    "        \n",
    "    # Scatter plots - n_clusters\n",
    "    scatterplot(df, x='n_clusters', y='ratio_AB_median', title=r'Relation between n_clusters and $\\frac{median(t_A)}{median(t_B)}$', xlabel='', ylabel=r'$\\frac{median(t_A)}{median(t_B)}$')\n",
    "    scatterplot(df, x='n_datapoints', y='ratio_AB_median', title=r'Relation between n_datapoints and $\\frac{median(t_A)}{median(t_B)}$', xlabel='n', ylabel=r'$\\frac{median(t_A)}{median(t_B)}$')\n",
    "    scatterplot(df, x='n_features', y='ratio_AB_median', title=r'Relation between n_features and $\\frac{median(t_A)}{median(t_B)}$', xlabel='d', ylabel=r'$\\frac{median(t_A)}{median(t_B)}$')\n",
    "    #scatterplot(df.groupby(['n_clusters']).mean(), x='n_clusters', y='ratio_AB_median', title=r'Relation between n_clusters and $\\frac{median(t_A)}{median(t_B)} - aggregation over all datasets $', xlabel='Number of clusters', ylabel=r'$\\frac{median(t_A)}{median(t_B)}$')\n",
    "    #scatterplot(df[df.n_datapoints == df.iloc[0].n_datapoints], x='n_clusters', y='ratio_AB_median', title=r'Relation between n_clusters and $\\frac{median(t_A)}{median(t_B)} - fixed dataset $', xlabel='Number of clusters', ylabel=r'$\\frac{median(t_A)}{median(t_B)}$')\n",
    "    \n",
    "    # Scatter plots - cluster sizes\n",
    "    df['ratio_max_min_cluster_size'] = df['max_cluster_size']/df['min_cluster_size']\n",
    "    scatterplot(df, x='median_cluster_size', y='ratio_AB_median', title=r'Relation between median(cluster_size) and $\\frac{median(t_A)}{median(t_B)}$', xlabel='Average cluster size', ylabel=r'$\\frac{median(t_A)}{median(t_B)}$')\n",
    "    scatterplot(df, x='ratio_max_min_cluster_size', y='ratio_AB_median', title=r'Relation between skew in cluster size (i.e:  $\\frac{max(cluster-size)}{min(cluster-size)}$) and  $\\frac{median(t_A)}{median(t_B)}$', xlabel=r'Skew: $\\frac{max(cluster-size)}{min(cluster-size)}$', ylabel=r'$\\frac{median(t_A)}{median(t_B)}$')\n",
    "    scatterplot(df, x='ratio_max_min_cluster_size', y='t_A_median', title=r'Relation between skew in cluster size (i.e:  $\\frac{max(cluster-size)}{min(cluster-size)}$) and median(t_A)', xlabel=r'Skew: $\\frac{max(cluster-size)}{min(cluster-size)}$', ylabel='median(t_A)')\n",
    "    scatterplot(df, x='ratio_max_min_cluster_size', y='t_B_median', title=r'Relation between skew in cluster size (i.e: $\\frac{max(cluster-size)}{min(cluster-size)}$)', xlabel=r'Skew: $\\frac{max(cluster-size)}{min(cluster-size)}$', ylabel='median(t_B)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8089a4-77b8-4521-8671-5402e2ccc1d5",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed758119-8f18-4b05-963f-b39afd4636f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_linear_regression(df, x_name, y_name):\n",
    "    X = df[x_name].to_numpy().reshape(-1, 1)  \n",
    "    y = df[y_name].to_numpy()\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y);\n",
    "    print(f'Model with x: {x_name}, y: {y_name}')\n",
    "    print(f'\\tCoefficient: {model.coef_}')\n",
    "    print(f'\\tIntercept: {model.intercept_}')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "556ec75c-8fcf-4b72-80d0-673cde72588d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataset(df):\n",
    "    # Remove inf values\n",
    "    df_clean = df.replace([np.inf, -np.inf], np.nan)\n",
    "    df_clean = df_clean.dropna()\n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63ebdb2-8faf-468f-a536-8bf6964a7a5c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Relation tA/tB, n, k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4912ffa-80f8-4e0e-8df7-6d08bdeb26f3",
   "metadata": {},
   "source": [
    "The implementations of kmeans should have the following complexities:\n",
    "- Assignment: **O(ndk)**\n",
    "- Update: **O(d(n+k))**\n",
    "\n",
    "Even if ideally the complexity of the update should be O(nd) since we are doing only nd suns, we need some work to separate the datapoints using the labels. This leads to extra work which depdends on k. Depending on the implementations we may have the update with complexity O(ndk) or O(d(n+k)). The fastest implementation in numpy is O(d(n+k)).\n",
    "\n",
    "We therefore expect to have: tA/tB O(nk/(n+k)).\n",
    "However, we have that usually n >> k, therefore O(nk/(n+k)) ~ O(k).\n",
    "\n",
    "In this case we have that:\n",
    "- for fixed n, the ratio tA/tB will grow like k. In particular:\n",
    "    - The assignment phase will grow with k, since O(ndk)\n",
    "    - The update phase should be costant with k, since O(d(n+k)) ~ O(dn)\n",
    "- for fixed k, the ratio tA/tB stay costant around k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4714d57d-2630-45cc-bf44-84f65b246f27",
   "metadata": {},
   "source": [
    "### Relation tA/tB, k\n",
    "\n",
    "We fix n (and d) and we plot the evolution of tA/tB for growing k.\n",
    "We take the dataset with relatively large d = 17."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfb6ece-fd10-4c20-af8e-65eb1392f29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "measure=False\n",
    "if measure:\n",
    "    # We select the first dataset in the list of datasets\n",
    "    X = X_list[-1]\n",
    "    df = pd.DataFrame(columns=['n_datapoints', 'n_features', 'n_clusters', 't_A_median', 't_A_min', 't_A_max', 't_B_median', 't_B_min', 't_B_max', 'median_cluster_size', 'min_cluster_size', 'max_cluster_size'])\n",
    "    i = 0\n",
    "    for K in range(3, 100):\n",
    "        if K%10 == 0:\n",
    "            print(K)\n",
    "        labels, centroids, A_time, B_time = KMeans(X, K, num_iter=100, measure=True)\n",
    "        # Get cluster size\n",
    "        clusters_size = np.array([X[labels == k].shape[0] for k in range(K)])\n",
    "        # Append to df\n",
    "        df.loc[i] = [X.shape[0], X.shape[1], K, np.median(A_time), np.min(A_time), np.max(A_time), np.median(B_time), np.min(B_time), np.max(B_time), np.nanmean(clusters_size), np.nanmin(clusters_size), np.nanmax(clusters_size)]\n",
    "        i += 1\n",
    "    df.to_csv('./data/measurements_relation_k.csv', index=False)\n",
    "    \n",
    "# Import dataset    \n",
    "df = pd.read_csv('./data/measurements_relation_k.csv')\n",
    "# Compute ratio\n",
    "df['ratio_AB_median'] = df['t_A_median']/df['t_B_median']\n",
    "# Clean dataset\n",
    "df_clean = clean_dataset(df)\n",
    "# Plot\n",
    "scatterplot(df_clean, 'n_clusters', 't_A_median', 'Relation k, ratio_AB', 'k', 'ratio_AB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1f72b1-9c92-412c-ae92-77faddefc400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit linear regression\n",
    "model_k_1 = fit_linear_regression(df_clean, 'n_clusters', 't_A_median')\n",
    "model_k_2 = fit_linear_regression(df_clean, 'n_clusters', 't_B_median')\n",
    "model_k_3 = fit_linear_regression(df_clean, 'n_clusters', 'ratio_AB_median')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f211594b-b3bf-4ae1-bee2-4c18af3f5d89",
   "metadata": {},
   "source": [
    "### Relation tA/tB, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6c97ff-6725-4d28-b28f-6195c192faf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if measure:\n",
    "    X_full = X_list[-1]\n",
    "    df = pd.DataFrame(columns=['n_datapoints', 'n_features', 'n_clusters', 't_A_median', 't_A_min', 't_A_max', 't_B_median', 't_B_min', 't_B_max', 'median_cluster_size', 'min_cluster_size', 'max_cluster_size'])\n",
    "    i = 0\n",
    "    K = 4\n",
    "    for j in range(1,101):\n",
    "        if j%10 == 0:\n",
    "            print(j)\n",
    "        X = X_full[:int(X_full.shape[0]* j/100)]\n",
    "        labels, centroids, A_time, B_time = KMeans(X, K, num_iter=100, measure=True)\n",
    "        # Get cluster size\n",
    "        clusters_size = np.array([X[labels == k].shape[0] for k in range(K)])\n",
    "        # Append to df\n",
    "        df.loc[i] = [X.shape[0], X.shape[1], K, np.median(A_time), np.min(A_time), np.max(A_time), np.median(B_time), np.min(B_time), np.max(B_time), np.nanmean(clusters_size), np.nanmin(clusters_size), np.nanmax(clusters_size)]\n",
    "        i += 1\n",
    "    df.to_csv('./data/measurements_relation_n.csv', index=False)\n",
    "    \n",
    "# Import dataset\n",
    "df = pd.read_csv('./data/measurements_relation_n.csv')\n",
    "# Compute ratio\n",
    "df['ratio_AB_median'] = df['t_A_median']/df['t_B_median']\n",
    "# Clean dataset\n",
    "df_clean = clean_dataset(df)\n",
    "# Scatterplot\n",
    "scatterplot(df_clean, 'n_datapoints', 'ratio_AB_median', 'Relation k, ratio_AB', 'n', 'ratio_AB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e1e124-7c3f-4663-a7f0-a45deab6fbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_n = fit_linear_regression(df,'n_datapoints', 'ratio_AB_median')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7fa455-7797-4bcd-99cd-23d87f7e9a0a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Measurements basic k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66acb76-3291-4061-9e92-49395a8566f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing 0° dataset...\n",
      "3 -- 4 -- 5 -- 6 -- 7 -- 8 -- 9 -- 10 -- 11 -- 12 -- 13 -- 14 -- \n",
      "Processing 1° dataset...\n",
      "3 -- 4 -- "
     ]
    }
   ],
   "source": [
    "if measure:\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "        i = 0\n",
    "        df_measurements = pd.DataFrame(columns=['n_datapoints', 'n_features', 'n_clusters', 't_A_median', 't_A_min', 't_A_max', 't_B_median', 't_B_min', 't_B_max', 'median_cluster_size', 'min_cluster_size', 'max_cluster_size'])\n",
    "        for k, X in enumerate(X_list):\n",
    "            print(f\"\\nProcessing {k}° dataset...\")\n",
    "            for K in range(3, 15):\n",
    "                # Fit kmeans\n",
    "                print(f\"{K} -- \", end='')\n",
    "                labels, centroids, A_time, B_time = KMeans(X, K, num_iter=100, measure=True)\n",
    "                # Get cluster size\n",
    "                clusters_size = np.array([X[labels == k].shape[0] for k in range(K)])\n",
    "                # Append to df\n",
    "                df_measurements.loc[i] = [X.shape[0], X.shape[1], K, np.median(A_time), np.min(A_time), np.max(A_time), np.median(B_time), np.min(B_time), np.max(B_time), np.nanmean(clusters_size), np.nanmin(clusters_size), np.nanmax(clusters_size)]\n",
    "                i += 1\n",
    "        df_measurements.to_csv('./data/measurements.csv', index=False)\n",
    "        \n",
    "df_measurements = pd.read_csv('./data/measurements.csv')\n",
    "getPlots(df_measurements)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70249774-c636-41d3-a167-7625ab86abe5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Measurements speculated k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20e80ab-40ac-42de-97b5-85d1436a8a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if measure:\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "        i = 0\n",
    "        subsample_size=0.01\n",
    "        df_measurements_speculation = pd.DataFrame(columns=['n_datapoints', 'n_features', 'n_clusters', 't_A_median', 't_A_min', 't_A_max', 't_B_median', 't_B_min', 't_B_max', 'median_cluster_size', 'min_cluster_size', 'max_cluster_size',\\\n",
    "                                                't_speculation_median', 't_speculation_min', 't_speculation_max', 't_correction_median', 't_correction_min', 't_correction_max', 'subsample_size'])\n",
    "        for k, X in enumerate(X_list):\n",
    "            print(f\"\\nProcessing {k}° dataset...\")\n",
    "            for K in range(3, 15):\n",
    "                # Fit kmeans\n",
    "                print(f\"{K} -- \", end='')\n",
    "                labels, centroids, A_time, B_time, speculation_time, correction_time  = KMeans_speculation(X, K, num_iter=100, measure=True, subsample_size = subsample_size)\n",
    "                # Get cluster size\n",
    "                clusters_size = np.array([X[labels == k].shape[0] for k in range(K)])\n",
    "                # Append to df\n",
    "                df_measurements_speculation.loc[i] = [X.shape[0], X.shape[1], K, np.median(A_time), np.min(A_time), np.max(A_time), np.median(B_time),\\\n",
    "                                          np.min(B_time), np.max(B_time), np.nanmean(clusters_size), np.nanmin(clusters_size), np.nanmax(clusters_size),\\\n",
    "                                          np.median(speculation_time), np.min(speculation_time), np.max(speculation_time), np.median(correction_time), np.min(correction_time), np.max(correction_time), subsample_size]\n",
    "                i += 1\n",
    "        df_measurements_speculation.to_csv('./data/measurements_speculation.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916f438f-6f1c-4ed7-a08a-7d85dbb56a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_measurements_speculation = pd.read_csv('./data/measurements_speculation.csv')\n",
    "getPlots(df_measurements_speculation, speculation = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b67fd1d-7b27-4348-841e-dc85555c5f5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
